{
    "start-title": "O início da jornada",
    "start-content": "Sou Bacharel em Ciências Contábeis pela Universidade Federal de Pernambuco. Ao longo da minha carreira assumi o cargo de gerente administrativo, onde desenvolvi habilidades sólidas em análise financeira, gestão de equipes e otimização de processos empresariais. Essa experiência me deu uma compreensão profunda de como os dados podem impulsionar decisões estratégicas e melhorias operacionais.",
    "the-way-title": "O caminho",
    "the-way-content-1": "Nos últimos anos, descobri uma nova paixão: a análise de dados. Tenho me dedicado a aprender linguagens de programação como Python, SQL além de me familiarizar com ferramentas de visualização de dados como Tableau e Power BI. Minha experiência contábil me proporcionou uma base sólida para interpretar e analisar dados com precisão e atenção aos detalhes.",
    "the-way-content-2": "A transição para a análise de dados é um desafio que estou ansioso para enfrentar. Adoro a ideia de combinar meus conhecimentos contábeis e administrativos com técnicas avançadas de análise de dados para gerar insights valiosos e tomar decisões informadas. Acredito que minha capacidade de comunicar informações complexas de maneira clara e acessível será um grande trunfo nessa nova jornada.",
    "the-way-content-3": "Estou determinado a avançar ainda mais e me tornar um Cientista de Dados. Nesse papel, pretendo aprofundar meu conhecimento em Machine Learning, estatística e análise preditiva para resolver problemas complexos e desenvolver modelos avançados que possam prever tendências e otimizar processos.",
    "The-ultimate-goal-title": "O objetivo final",
    "The-ultimate-goal-content": "Finalmente, meu sonho é me tornar um Engenheiro de Inteligência Artificial. Vejo a inteligência artificial como a fronteira final da área de dados, onde posso aplicar tudo o que aprendi para criar soluções inovadoras e inteligentes. Estou comprometido com o aprendizado contínuo e a adaptação às rápidas mudanças tecnológicas, e acredito que minha paixão por resolver problemas e minha experiência multifacetada me prepararão bem para esse futuro.",
    "banner-resume": "Minha experiência em contabilidade me proporcionou uma forte base em análise financeira, atenção aos detalhes e tomada de decisões baseada em dados. Como gerente administrativo, desenvolvi habilidades em liderança, gestão de equipes e otimização de processos. Essas competências são complementares à Ciência de Dados, onde pretendo aplicar meu conhecimento para a resolução dos problemas de negócios, a extração de insights significativo e apoiar a tomada de decisões estratégicas motivado pela evolução constante do mercado.",
    "analytical-thinking-title": "Pensamento Analítico",
    "analytical-thinking-content": "Esta habilidade me permite enfrentar desafios de forma estruturada e eficiente, contribuindo para minha capacidade de resolver problemas de maneira criativa e encontrar soluções inovadoras.",
    "continuous-learning-title": "Aprendizado Contínuo",
    "continuous-learning-content": "Estou sempre em busca de novos conhecimentos e experiências, seja por meio da leitura, da pesquisa, da interação com outras pessoas ou da exploração. Encaro cada oportunidade como uma chance de crescimento e desenvolvimento pessoal.",
    "comunication-title": "Comunicação",
    "comunication-content": "Sou hábil em expressar minhas ideias de maneira clara e concisa, adaptando meu estilo de comunicação conforme o contexto e a audiência. Sou um bom ouvinte capaz de articular minhas próprias ideias com confiança e persuasão.",
    "sql-title": "SQL",
    "sql-content": "Tenho um entendimento sólido dos princípios fundamentais da linguagem e posso trabalhar de forma independente na maioria das tarefas relacionadas a bancos de dados por meio de operações de junção, filtragem e ordenação de dados com confiança.",
    "python-title": "Python",
    "python-content": "Estou confortável com a sintáxe do Python, incluindo estruturas de controle de fluxo, tipos de dados, funções e manipulação de dados. Além disso, tenho experiência na utilização de bibliotecas populares como NumPy, Pandas, Matplotlib e Seaborn para análise e visualização de dados",
    "dataviz-title": "Visualização de Dados",
    "dataviz-content": "Tenho conhecimento sobre como escolher o tipo correto de gráfico para representar diferentes tipos de dados, bem como sobre como aplicar formatação, cores e rótulos para tornar as visualizações mais compreensíveis e atraentes por meio do storytelling utilizando Power BI, Tableu, Looker Studio.",
    "side-bar-main-projects": "Pricipais Projetos",
    "button-see": "Ver projeto",
    "objective-definition": "Definição do objetivo",
    "collect-extract": "Coleta e Extração de Dados",
    "choice-tools": "Escolha de Ferramentas",
    "techniques": "Aplicação das técnicas de análise",
    "results": "Resultados",
    "tools": "Ferramentas utilizadas",
    "related-projects": "Projetos Relacionados",
    "projects-title": "Projetos",

    "amz-index": "Análise Descritiva sobre os preço, desconto e avaliação dos produtos vendidos na da divisão Indiana da Amazon, aplicando estatística buscando correlação entre as variáveis.",
    "amz-bi-page-theme": "Utilizamos dados da filial Indiana da gigante varejista para realizar uma análise descritiva de como estão distribuídos os produtos por categoria, as avaliações, preço, desconto e correlação entre avaliação e valor do produto.",
    "amz-obj": "Iremos analisar um conjunto de dados públicos disponibilizado no Kaggle sobre dados de vendas da filial Indiana da Amazon.",
    "amz-tech-1": "Limpeza e Pré-processamento",
    "amz-tech-2": "Análise Exploratória",
    "amz-tech-3": "Análise Descritiva",
    "amz-results-1": "Utilizamos alguns Cartões para Visualizarmos Total de Produtos, Média Geral de Avaliação, Maior Quantidade de Avaliações em um único produto e Total Geral de Avaliações.",
    "amz-results-2": "Através Gráfico de Barras Horizontal para entendermos a distribuição dos produtos por categoria.",
    "amz-results-3": "Destacamos por meio do Gráfico de Pizza as 3 Categorias de Produtos com Mais Avaliações.",
    "amz-results-4": "Avaliamos a Quantidade Média de Avaliações dos Produtos divididos por Categorias.",
    "amz-results-5": "Nesta Página destacamos alguns indicadores:",
    "amz-results-6": "Maior Valor Absoluto de Desconto",
    "amz-results-7": "Produto de Menor Valor - Mini USB Type C Adapter Plug",
    "amz-results-8": "Maior Desconto Percentual Aplicado",
    "amz-results-9": "Produto de Maior Valor - Sony (65 inches) 4K Smart LED TV",
    "amz-results-10": "Utilizamos gráficos de barras para analisarmos as Médias de Desconto Absoluto e Percentual por Categoria e Produto.",
    "amz-results-11": "Segmentamos por Faixa os Produtos por Preço, Desconto e Avaliação.",
    "amz-results-12": "Podemos visualizar no gráfico de dispersão que há uma correlação levemente positiva entre o Total de Avaliações e a Avaliação os produtos analisados.",
    "amz-results-13": "Podemos visualizar no gráfico de dispersão que há uma correlação levemente positiva entre o Preço Final dos produtos com desconto e a Avaliações dos produtos analisados.",
    "amz-results-14": "Podemos visualizar no gráfico de dispersão que há uma correlação levemente negativa entre a Porcentagem de Desconto do produtos e a Avaliações dos produtos analisados.",
    "amz-results-15": "Página utilizada para reportar possíveis atualizações do Dashboard.",

    "data-index": "EDA utilizando Pandas e Seaborn para analisar dados sobre os salários dos profissionais da área dados de nível global.",
    "data-bi-page-theme": "Neste projeto iremos nos aprofundar em como se configura a remuneração dos profissionais da área de dados em nível Global. Utilizaremos a segmentação geográfica, nível de experiência, modelo de trabalho, tamanho da companhia, entre outros.",
    "data-obj": "Iremos analisar um conjunto de dados públicos disponibilizado no Kaggle sobre os Salários dos profissionais da Área de Dados.",
    "data-tech-1": "Limpeza e Pré-processamento",
    "data-tech-2": "Análise Exploratória",
    "data-tech-3": "Análise Descritiva",
    "data-results-1": "Na página principal evidenciamos a média de salarial total, assim como valores máximos, mínimos e quantidade de profissões diferentes.",
    "data-results-2": "A partir da utilização do filtro retrátil podemos segmentar os dados de acordo com nível de experiência e por categoria.",
    "data-results-3": "Nesta página utilizando uma tabela listamos todas as profissões descritas na pesquisa.",
    "data-results-4": "Utilizando gráficos de barras horizontais segmentamos a quantidade de profissionais de acordo com a modalidade de trabalho e o tamanho da companhia que estão associados.",
    "data-results-5": "Na última página o objetivo foi mostrar a distribuição global.",
    "data-results-6": "Podemos utilizar o filtro para segmentar por Continent, País, Residência do Empregado e Local da Companhia.",
    "data-results-7": "Conseguimos também visualizar a quantidade de cada profissional de acordo com experiência e sua média salarial.",

    "olist-index": "Neste projeto foi construído um Data Warehouse através do SQL Server utilizando dados da Olist, plataforma de Ecommerce Brasileira que conecta o lojista ao consumidor final.",
    "olist-da-page-theme": "Construímos um pequeno projeto de Data Warehouse a partir de dados fornecidos da Olist, startup de ecommerce brasileira que conecta vendedores e logistas ao cliente. Foi utilizado SQL Server para a modelagem de dados, Figma para construção do background e Microsoft Power BI para montagem do Dashboard.",
    "techniques-olist": "Aplicação das técnicas de Modelagem/Limpeza/Imputação",
    "olist-obj-1": "Neste projeto utilizaremos o conjunto de dados públicos do ecommerce brasileiro, disponibilizado pela Olist, Startup que atua no segmento de tecnologia para o varejo;",
    "olist-obj-2": "A Olist conecta pequenas empresas do Brasil a canais de comunicação para que os comerciantes possam vender seus produtos através da web e enviá-los diretamente para os clientes usando os parceiros logísticos;",
    "olist-obj-3": "Os dados foram obtidos na plataforma Kaggle no formato CSV, utilizamos o SQL Server 2022 como SGBD e SQL Server Management Studio para realizar as consultas necessárias;",
    "olist-obj-4": "O primeiro passo foi configurar a instância necessária no SQL Server;",
    "olist-obj-5": "Depois partimos para a importação dos arquivos CSV;",
    "olist-obj-6": "Criamos as tabelas necessárias para melhor seleção e gerenciamento dos dados necessários para o projeto;",
    "olist-tech-SQL-title": "SQL - Modelagem/Limpeza/Imputação",
    "olist-tech-1": "Observamos que para um mesmo prefixo pode conter diversas latitudes e longitudes, sempre indicando a mesma cidade e estado, ou seja o prefixo é usado de forma genérica pois está incompleto assim não conseguimos associar a localização exata como bairro e rua, portanto podemos manter somente 1 valor de prefixo já que irá indicar a somente a cidade e o estado.",
    "olist-tech-1.1": "Isso ajudará a diminuir a quantidade de registros e consequentemente o tempo de carregamento e conexão entre os dados no Power BI que não consegue reconhecer o relacionamento entre as tabelas pois há duplicidade;",
    "olist-tech-2": "Criaremos as Tabelas Dimensão e Fato, com suas respectivas Natural Keys e Surrogate Keys para a Modelagem Dimensional do DataWarehouse;",
    "olist-tech-3": "Iremos criar uma Function reutilizavei para substituir as siglas dos estados por nome completo, pois a abreviação pode ser vinculada a estados de outros países;",
    "olist-tech-4": "Criaremos uma tabela dimensão calendario no DW para melhor análise temporal no Power BI;",
    "olist-tech-dax-title": "DAX - Medidas/Funções",
    "olist-tech-5": "Criação de Medidas(CALCULATE,SUM,AVERAGE,COUNT,DISTINCTCOUNT) para utilizar na geração de resultados.",
    "olist-tech-6": "Utilização da função CROSSFILTER para fazer a ligação das tabelas dimensão e evitar o uso da direção ambos que podem gerar ambiguidade;",
    "olist-tech-powerquery-title": "Power Query - Substitução/Transformação",
    "olist-tech-7": "Substituição dos valores na tabela dimensão calendário para Dia da Semana e Mês em inglês;",
    "olist-tech-8": "Tranformação dos valores na coluna categoria de produtos para retirada do '_' e elevar primeiro caracter a Maíusculo em cada primeira letra das palavras;",
    "olist-tech-9": "Elevação do primeiro caracter de cada palavra da coluna cidades a Maíusculo;",
    "olist-tech-10": "Correção de registros que podem ser agregados a mesma cidade;",
    "olist-model": "Assim ficou o Modelo Dimensional do Data Warehouse em Star Schema.",
    "olist-describe": "Foi criado um quadro descritivo dos dados da Olist que pode ser acessado clicando na logo.",
    "olist-filter": "Os resultados podem ser segmentados por estados através do Painel de Filtro retrátil.",
    "olist-results-page-main": "Página Principal",
    "olist-results-1": "Quantidade Total de Clientes - Cartão;",
    "olist-results-2": "Quantidade Total de Vendedores - Cartão;",
    "olist-results-3": "Média Geral de Avaliação - Cartão;",
    "olist-results-4": "Quantidade Total de Produtos - Cartão;",
    "olist-results-5": "Quantidade Total de Categorias - Cartão",
    "olist-results-6": "Tabela 1 - Quantidade de Pedidos por Status;",
    "olist-results-7": "Tabela 2 - Média de Avaliação por Categoria;",
    "olist-results-8": "Gráfico 1 - Gráfico de Barras Horizontal Quantidade Total de Clientes por Cidade;",
    "olist-results-9": "Gráfico 2 - Gráfico de Barras Horizontal Quantidade Total de Clientes por Estado;",
    "olist-results-10": "Gráfico 3 - Gráfico de Barras Vertical Quantidade de Pedidos por Tipo de Pagamento;",
    "olist-results-page-finance": "Página Financeira",
    "olist-results-11": "Valor médio do Pedidos - Cartão;",
    "olist-results-12": "Pedido de Valor mais Alto - Cartão;",
    "olist-results-13": "Receita Total - Cartão;",
    "olist-results-14": "Tabela 3 - Receita Total por Tipo de Status;",
    "olist-results-15": "Gráfico 4 - Funil Rank Estados com maior Receita;",
    "olist-results-16": "Gráfico 5 - Gráfico de Barras Receita Total por Tipo de Pagamento;",
    "olist-results-17": "Gráfico 6 - Gráfico de Barras Horizontal Rank Receita por Categoria de Produtos;",
    "olist-results-page-historical": "Página Histórico",
    "olist-results-18": "Gráfico 7 - Gráfico de Linha Concentração do volume de compras (Dia da Semana);",
    "olist-results-19": "Gráfico 8 - Gráfico de Área Concentração do volume de compras (Dia);",
    "olist-results-20": "Gráfico 9 - Gráfico de Área Concentração do volume de compras (Hora);",
    "olist-results-21": "Gráfico 10 - Gráfico de Área Concentração do volume de compras (Mês);",
    "olist-filter-historical": "Nesta página os resultado também podem ser filtrados por ano.",

    "foodgood-index": "Utilizando técnicas de ETL criei um Data Warehouse para ser carregador através do SQL Server Integration Service e realizar a análise descritiva (EDA) descritiva da plataforma de entrega brasileira Delivery Center.",
    "foodgood-da-page-theme": "Neste projeto de Data Warehouse utilizei o SSIS para realizar a carga dos dados do Banco Relacional hospedado no SQL Server para o Data Warehouse de uma plataforma de Delivery responsável por vendas de Alimentos e Bens de Consumo, poderemos analisar os números abusolutos, regionais e financeiros dos pedidos, lojas e cidades onde estão localizados os pontos de venda e centros de distribuição.",
    "describe-foodgood-title": "Descrição do Projeto",
    "foodgood-describe-1": "O Delivery Center é um plataforma que integra logistas e marketplaces, criando um ecossistema logístico que permite a venda de bens de consumo(GOOD) e alimentos(FOOD) no varejo brasileiro.",
    "foodgood-describe-2": "Este modelo representa dados fictícios de pedidos e entregas que foram processadas entre os meses de Janeiro e Abril de 2021, não representa sua completude e alguns dados foram alterados para preservar os clientes de acordo com a LGPD.",
    "foodgood-describe-3": "Suas centrais de distruição(hubs) estavam localizadas em shoppings de algumas capitais do Brasil, neste conjunto de dados foram fornecidos dados de Curitiba, Porto Alegre, Rio de Janeiro e São Paulo.",
    "foodgood-describe-4": "A empresa fundada em 2016 obteve relativo sucesso ao longo da sua trajetória, principalmente durante a pandemia da COVID-19 em 2020, porém encerrou suas operações em 2021 após conflitos entre aos acionistas, concorrência acirrada e uma queda abrupta de faturamento.",
    "foodgood-obj-1": "Neste Data Warehouse iremos sintetizar os dados de forma a obtermos insights sobre quantidades absolutas, distribuição regional e como foi o comportamento financeiro da empresa no período analisado;",
    "foodgood-obj-2": "Utilizaremos o conjunto de dados para criar um Data Warehouse através do SQL Server Integration Services(SSIS);",
    "source": "Fonte de Dados",
    "source-describe-1": "channels: informações relativas aos canais de venda onde são vendidos os Good e Food;",
    "source-describe-2": "deliveries: dados sobre as entregas;",
    "source-describe-3": "drivers: dados sobre os entregadores;",
    "source-describe-4": "hubs: informações sobre as centrais;",
    "source-describe-5": "orders: dados sobre os pedidos realizados;",
    "source-describe-6": "payments: informações sobre os pagamentos realizados;",
    "source-describe-7": "stores: dados sobre as lojas que utilizam a plataforma;", 
    "foodgood-SSIS": "Modelagem Data Warehouse",
    "foodgood-tech-1": "Primeiro iremos inserir os dados em CSV obtidos no Kaggle no SQL Server",
    "foodgood-tech-2": "Em seguida após realizar a conexão do SSIS com o SQL Server iremos simular uma carga de dados do Banco de Dados relacional criado no SQL Server para o Data Warehouse que será criado ao fim de cada tarefa no Data Flow, não realizaremos nenhuma transformação no SSIS, deixaremos essa etapa para projetos futuros em ferrametas mais específicas, portanto ficará simples a carga dos dados utilizando OLE DB da seguinte forma:",
    "foodgood-tech-3": "O Data Flow da carga de dados das tabelas dimensão:",
    "foodgood-tech-4": "A segunda etapa será a carga da tabela Fato:",
    "foodgood-tech-5": "Por último iremos automazizar o fluxo de carregamento de dados:",
    "foodgood-tech-6": "Assim ficará o Modelo Dimensional do Data Warehouse:",
    "foodgood-tech-7": "Abaixo encontrará o script SQL para consulta do Banco de Dados Relacional e a criação do Data Warehouse:",
    "foodgood-describe": "Na visualização dos dados foi utilizado o Power BI com personalização do plano de fundo com o Figma baseando-se com elementos de UI/UX e Storytelling.",
    "foodgood-cleaning": "No PowerQuery aplicamos as transformações necessárias para a limpeza dos dados, conversão, imputação, remoção de outliers e engenharia de atributos.",
    "foodgood-filter": "Foi criado um filtro retrátil para utilizar segmentação de dados.",
    "foodgood-results-page-home": "Na primeira página realizei uma análise dos números absolutos para obtermos insights de como está a distribuição dos pedidos de acordo com os seguintes parâmetros:",
    "foodgood-results-1": "Vendas por dia da semana podemos observar que há uma sazonalidade onde a maior parte das vendas 49% do total das 358.654 realizadas ocorre no final de semana.",
    "foodgood-results-2": "88% do total de vendas absolutas é representada pelo segmento de Alimentos.",
    "foodgood-results-3": "71% das entregas são realizadas por trabalhadores Freelancer sem nenhum vínculo empregatício com os logistas.",
    "foodgood-results-4": "69% dos entregadores utilizando motocicletas como veículo para realizar as entregas.",
    "foodgood-results-5": "Os meses de Abril e Março representam 59% das vendas, com destaque para Março onde houve 109mil pedido realizados.",
    "foodgood-results-6": "Em sua maioria os pedidos foram entregues totalizando 98% do total.",
    "foodgood-results-7": "A plataforma do Delivery Center foi responsável por 90% do pedidos realizados, somente 10% dos logistas utilizaram aplicativos próprios.",
    "foodgood-results-page-region": "Nesta página o objetivo foi realizar uma análise sobre as cidades em que as lojas estão alocadas e como está se comportando o tempo médio de entrega, a quantidade absoluta de lojas e vendas por lojas e também de como está a representatividade financeira das lojas.",
    "foodgood-results-8": "951 lojas foram contabilizadas, em 32 hubs diferentes, localizados em 4 capitais brasileiras.",
    "foodgood-results-9": "O tempo médio geral de entrega 178min - 3h sofreu uma grande influência do segmento de de bens(GOOD) 893min - 15 horas que por não serem produtos perecíves não necessitavam de urgência, enquanto que para os alimentos(FOOD) a média ficou em 84min.",
    "foodgood-results-10": "No quesito números absolutos de pedidos São Paulo foi responsável por 45% dos pedidos seguido por Rio de Janeiro com 38% dos pedidos.",
    "foodgood-results-11": "O Hub Golden Shopping localizado na cidade do Rio de Janeiro foi o campeão de faturamento, representando 10.7% do total, porém 4 das próximo 5 posições são de Hubs localizando em São Paulo, assim nos mostra que de forma absoluta São Paulo além da quantidade de pedidos é o maior responsável por faturamento do conjunto de dados.",
    "foodgood-results-page-finance": "Na página Finance o objetivo foi analisar de forma detalhada como se comportou os números financeiros do conjunto de dados como valor do pedido, custo, extornos realizados, valor médio, comportamento ao longo tempo e os métodos de pagamento mais utilizados.",
    "foodgood-results-12": "O primeiro cartão nos mostra que o faturamento total gerado foi aproximadamente R$37.2M enqunato o custo aproximadamente R$3M, assim o Lucro gerado aproximadamente R$34.2M, o valor do estorno de R$7.161 não foi representativo para o cálculo do Lucro.",
    "foodgood-results-13": "O valor médio do pedido ficou em R$92.8 depois de realizado o tratamento de Outlier que eliminou um único pedido do valor de R$100K, no último cartão apresentei o valor médio da taxa cobrada R$1.88.",
    "foodgood-results-14": "Observando o gráfico representando o faturamento e o custo ao longo do tempo é possível perceber que coincide com o gráfico apresentando o número de pedidos na página inicial, onde temos uma relativa paridade em Janeiro e Feveiro seguindo de um crescimento em Março e voltando a diminuir em Abril.",
    "foodgood-results-15": "No quesito método de pagamento o em disparada temos o método online, porém é importante observamos que essa é uma descrição genérica, pois alguns dos outros métodos de pagamentos também podem ser realizados de forma Online, como cartão de crédito e transferência bancária, então é possível que essa categoria seja referente a pagamentos realizados através da plataforma e não no momento de entrega ou retirada.",
    "foodgood-results-final": "O conjunto de dados utilizado na construção do Data Warehouse nos permitiu realizar análises importantes do comportamento absoluto, regional e financeiro da empresa em um momento de retomada da econômia pós pandemia da COVID-19. Para futuras análises poderia ser melhor compreendido as métricas relacionadas aos entregadores, como a quantidade de entregas realizadas, tempo médio de entrega, distância percorrida."

}